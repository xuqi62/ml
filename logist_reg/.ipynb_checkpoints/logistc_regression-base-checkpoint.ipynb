{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    " 来源于《机器学习实战》第五章逻辑回归,使用逻辑回归解决二分类问题。 \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init 11111\n",
      "data shape: (42000, 785)\n",
      "labelTrain[m-1], 1\n",
      "data shape: (42000, 784)\n",
      "xArr.shape: (784, 42000) (1, 42000)\n",
      "(1, 784)\n",
      "loss sum: [29112.18158352]\n",
      "loss sum: [4806.86770999]\n",
      "loss sum: [3632.12352701]\n",
      "loss sum: [3129.03400032]\n",
      "loss sum: [2832.05772575]\n",
      "loss sum: [2630.51392444]\n",
      "loss sum: [2482.50245393]\n",
      "loss sum: [2368.0812654]\n",
      "loss sum: [2276.35697971]\n",
      "loss sum: [2200.80218654]\n",
      "loss sum: [2137.23558488]\n",
      "loss sum: [2082.83952014]\n",
      "loss sum: [2035.63791167]\n",
      "loss sum: [1994.1992951]\n",
      "loss sum: [1957.45852171]\n",
      "loss sum: [1924.6048691]\n",
      "loss sum: [1895.00919418]\n",
      "loss sum: [1868.17500096]\n",
      "loss sum: [1843.70467746]\n",
      "loss sum: [1821.27564821]\n",
      "loss sum: [1800.62318049]\n",
      "loss sum: [1781.52775981]\n",
      "loss sum: [1763.80566821]\n",
      "loss sum: [1747.30184918]\n",
      "loss sum: [1731.88443219]\n",
      "loss sum: [1717.4404801]\n",
      "loss sum: [1703.87264977]\n",
      "loss sum: [1691.09654331]\n",
      "loss sum: [1679.03858767]\n",
      "loss sum: [1667.63432247]\n",
      "loss sum: [1656.82700669]\n",
      "loss sum: [1646.56647627]\n",
      "loss sum: [1636.80820125]\n",
      "loss sum: [1627.5125024]\n",
      "loss sum: [1618.6438966]\n",
      "loss sum: [1610.17054666]\n",
      "loss sum: [1602.06379662]\n",
      "loss sum: [1594.29777705]\n",
      "loss sum: [1586.84906852]\n",
      "loss sum: [1579.69641322]\n",
      "loss sum: [1572.82046686]\n",
      "loss sum: [1566.20358441]\n",
      "loss sum: [1559.82963427]\n",
      "loss sum: [1553.68383672]\n",
      "loss sum: [1547.75262273]\n",
      "loss sum: [1542.02351043]\n",
      "loss sum: [1536.48499654]\n",
      "loss sum: [1531.12646066]\n",
      "loss sum: [1525.93808083]\n",
      "loss sum: [1520.91075856]\n",
      "loss sum: [1516.03605241]\n",
      "loss sum: [1511.30611869]\n",
      "loss sum: [1506.71365867]\n",
      "loss sum: [1502.25187126]\n",
      "loss sum: [1497.91441066]\n",
      "loss sum: [1493.69534824]\n",
      "loss sum: [1489.58913833]\n",
      "loss sum: [1485.59058726]\n",
      "loss sum: [1481.69482544]\n",
      "loss sum: [1477.8972821]\n",
      "loss sum: [1474.19366232]\n",
      "loss sum: [1470.57992627]\n",
      "loss sum: [1467.0522702]\n",
      "loss sum: [1463.60710923]\n",
      "loss sum: [1460.24106156]\n",
      "loss sum: [1456.95093408]\n",
      "loss sum: [1453.73370923]\n",
      "loss sum: [1450.58653288]\n",
      "loss sum: [1447.50670324]\n",
      "loss sum: [1444.49166074]\n",
      "loss sum: [1441.53897861]\n",
      "loss sum: [1438.64635424]\n",
      "loss sum: [1435.81160127]\n",
      "loss sum: [1433.03264221]\n",
      "loss sum: [1430.30750165]\n",
      "loss sum: [1427.63429998]\n",
      "loss sum: [1425.01124756]\n",
      "loss sum: [1422.43663935]\n",
      "loss sum: [1419.90884986]\n",
      "loss sum: [1417.42632853]\n",
      "loss sum: [1414.98759536]\n",
      "loss sum: [1412.59123694]\n",
      "loss sum: [1410.23590264]\n",
      "loss sum: [1407.92030113]\n",
      "loss sum: [1405.64319714]\n",
      "loss sum: [1403.40340837]\n",
      "loss sum: [1401.19980264]\n",
      "loss sum: [1399.03129526]\n",
      "loss sum: [1396.89684649]\n",
      "loss sum: [1394.79545922]\n",
      "loss sum: [1392.72617678]\n",
      "loss sum: [1390.68808086]\n",
      "loss sum: [1388.68028958]\n",
      "loss sum: [1386.70195572]\n",
      "loss sum: [1384.75226494]\n",
      "loss sum: [1382.83043421]\n",
      "loss sum: [1380.93571031]\n",
      "loss sum: [1379.06736837]\n",
      "loss sum: [1377.22471055]\n",
      "loss sum: [1375.40706478]\n",
      "y_hat shape: (1, 42000)\n",
      "err rate: 0.9907857142857143\n"
     ]
    }
   ],
   "source": [
    "# %load lr.py\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self):\n",
    "        print(\"init 11111\")\n",
    "        self.__learning_rate = 0.000001\n",
    "        self.__lamda = 0.01\n",
    "        \n",
    "    def __sigmoid(self, x):    \n",
    "        return 1.0/(1+ np.exp(-x))      \n",
    "    \n",
    "    def gradDesc(self, data, label):\n",
    "        xMat = np.mat(data); yMat = np.mat(label).T\n",
    "        \n",
    "        xArr = np.array(data, dtype=np.float64).T / 255.0\n",
    "        n,m = xArr.shape\n",
    "        \n",
    "        yArr = np.array(label, dtype=np.float64).reshape(1, m)\n",
    "        \n",
    "        print(\"xArr.shape:\", xArr.shape, yArr.shape)\n",
    "        self.__W = np.zeros((1, n), dtype=np.float64)\n",
    "        self.__b = 0.0\n",
    "        print(self.__W.shape)\n",
    "        step = 10000\n",
    "        alpha = self.__learning_rate\n",
    "        \n",
    "        for i in range(step):\n",
    "            y_hat = self.__sigmoid(self.__W.dot(xArr) + self.__b)\n",
    "            loss = y_hat - yArr\n",
    "\n",
    "            self.__W = self.__W - alpha*loss.dot(xArr.T)\n",
    "\n",
    "            self.__b = self.__b - alpha*loss\n",
    "            if(i%100 == 0):\n",
    "                ones_array = np.ones((1, m))\n",
    "                \n",
    "                loss_arr = -yArr*np.log(y_hat)-(ones_array-yArr)*np.log(ones_array - y_hat)\n",
    "\n",
    "                loss = np.sum(loss_arr, axis=1)\n",
    "                print(\"loss sum:\", loss)\n",
    "        return self.__W\n",
    "    \n",
    "    def predict(self, testData, testLabel):\n",
    "        xArr = np.array(testData, dtype=np.float64).T / 255.0\n",
    "        n, m = xArr.shape\n",
    "        yArr = np.array(testLabel, dtype=np.float64).reshape(1, m)\n",
    "        \n",
    "        y_hat = self.__sigmoid(self.__W.dot(xArr) + self.__b)\n",
    "        print(\"y_hat shape:\", y_hat.shape)\n",
    "        \n",
    "        right = 0\n",
    "        for i in range(m):\n",
    "            if((yArr[0][i]==1) and (y_hat[0][i]>0.5)):\n",
    "                right += 1\n",
    "            elif ((yArr[0][i]==0) and (y_hat[0][i]<=0.5)):\n",
    "                right += 1\n",
    "        print (\"err rate:\", right / m)\n",
    "        return\n",
    "        \n",
    "\n",
    "    def plotwieght(self, weight, cycle_number):\n",
    "        fig = plt.fighre()\n",
    "        ax = fig.add_subplot(131)\n",
    "        ax.scatter(cycle_number, weight[0])\n",
    "        plt.show()\n",
    "\n",
    "    def plotBestFit(self, weight):\n",
    "        import matplotlib.pyplot as plt\n",
    "        dataMat,labelMat = loadDataSet(\"testSet.txt\")\n",
    "        xcord1=[]; ycord1=[]\n",
    "        xcord2=[]; ycord2=[]\n",
    "        dataArr = np.array(dataMat)\n",
    "        m,n = np.shape(dataMat)\n",
    "        for i in range(m):\n",
    "            if(int(labelMat[i]) == 1):\n",
    "                xcord1.append(dataArr[i,1]); ycord1.append(dataArr[i,2])\n",
    "            else:\n",
    "                xcord2.append(dataArr[i,1]); ycord2.append(dataArr[i,2])       \n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.scatter(xcord1, ycord1, s=30, c='red', marker='s')\n",
    "        ax.scatter(xcord2, ycord2, s=30, c='green')\n",
    "        x= np.arange(-3.0, 3.0, 0.1)\n",
    "        y = (-weight[0][0]-weight[0][1]*x)/weight[0][2]\n",
    "        ax.plot(x, y)\n",
    "        plt.xlabel('X1'), plt.ylabel('X2')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def loadDataSet(fileName):\n",
    "    numFeature = len(open(fileName).readline().split('\\t')) - 1\n",
    "    print (\"feature number: %d\" % numFeature)\n",
    "    dataMat = []; labelMat = []\n",
    "\n",
    "    with open(fileName) as myfile:\n",
    "        for line in myfile.readlines():\n",
    "            lineArr = []\n",
    "            curLine = line.split('\\t')\n",
    "            lineArr.append(1.0)\n",
    "\n",
    "            for i in range(numFeature):\n",
    "                lineArr.append(float(curLine[i]))\n",
    "            dataMat.append(lineArr)\n",
    "            labelMat.append(float(curLine[-1]))\n",
    "    #print (\"dataMat \", dataMat)\n",
    "    return dataMat,labelMat\n",
    "\n",
    "\n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "    lr = LogisticRegression();\n",
    " \n",
    "    #testSet is the simple dataSet\n",
    "    data,label = loadDataSet(\"testSet.txt\")\n",
    "\n",
    "    W1 = lr.gradDesc(dataTrain, labelTrain)\n",
    "    #W2 = lr.stocGradDesc1(xArr, yArr, 1500)\n",
    "\n",
    "    print(W1)\n",
    "\n",
    "    lr.plotBestFit(W1)\n",
    "'''\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    lr = LogisticRegression();\n",
    "    \n",
    "    raw_data = pd.read_csv(\"train.csv\", header=0)\n",
    "    values = raw_data.values\n",
    "    \n",
    "    m, n = values.shape\n",
    "    print (\"data shape:\", values.shape)\n",
    "    train_number = m*0.7\n",
    "    \n",
    "    dataTrain = values[0::, 1::]\n",
    "    label = values[0::, 0]\n",
    "    labelTrain = []\n",
    "    for i in range(m):\n",
    "        if(label[i] > 0):\n",
    "            labelTrain.append(1)\n",
    "        else:\n",
    "            labelTrain.append(0)\n",
    "    print(\"labelTrain[m-1],\", labelTrain[m-1])\n",
    "    \n",
    "    print(\"data shape:\", dataTrain.shape)\n",
    "    \n",
    "\n",
    "    W1 = lr.gradDesc(dataTrain, labelTrain)\n",
    "    #W2 = lr.stocGradDesc1(xArr, yArr, 1500)\n",
    "    \n",
    "    lr.predict(dataTrain, labelTrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
